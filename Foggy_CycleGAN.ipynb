{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ghaiszaher/Foggy-CycleGAN/blob/master/Foggy_CycleGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xnMOsbqHz61"
   },
   "source": [
    "# CycleFoggyGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Set up the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJ1ROiQxJ-vY"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lhSsUx9Nyb3t"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YfIk2es3hJEd"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYn4MdZnKCey"
   },
   "source": [
    "## Input Pipeline\n",
    "\n",
    "This tutorial trains a model to translate from images of A, to images of B. You can find this dataset and similar ones [here](https://www.tensorflow.org/datasets/datasets#cycle_gan). \n",
    "\n",
    "As mentioned in the [paper](https://arxiv.org/abs/1703.10593), apply random jittering and mirroring to the training dataset. These are some of the image augmentation techniques that avoids overfitting.\n",
    "\n",
    "This is similar to what was done in [pix2pix](https://www.tensorflow.org/tutorials/generative/pix2pix#load_the_dataset)\n",
    "\n",
    "* In random jittering, the image is resized to `286 x 286` and then randomly cropped to `256 x 256`.\n",
    "* In random mirroring, the image is randomly flipped horizontally i.e left to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CbTEt448b4R"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yn3IwqhiIszt"
   },
   "outputs": [],
   "source": [
    "def random_crop(image):\n",
    "  cropped_image = tf.image.random_crop(\n",
    "      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n",
    "\n",
    "  return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muhR2cgbLKWW"
   },
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "  image = (image * 2) - 1\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAa4Z9WProQs"
   },
   "outputs": [],
   "source": [
    "#back to range [0, 1]\n",
    "def denormalize(image):\n",
    "  image = (image + 1)/2.\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVQOjcPVLrUc"
   },
   "outputs": [],
   "source": [
    "def random_jitter(image):\n",
    "  # resizing to 286 x 286 x 3\n",
    "  image = tf.image.resize(image, [286, 286],\n",
    "                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "  # randomly cropping to 256 x 256 x 3\n",
    "  image = random_crop(image)\n",
    "\n",
    "  # random mirroring\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  \n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BqMY3EXXsmkT"
   },
   "outputs": [],
   "source": [
    "def rgb_to_hsv(image):  \n",
    "  image = tf.image.rgb_to_hsv(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVC17LGA6ZX5"
   },
   "outputs": [],
   "source": [
    "def hsv_to_hsl(image):\n",
    "  h = image[...,0:1]\n",
    "  s = image[...,1:2]\n",
    "  v = image[...,2:3]\n",
    "\n",
    "  l = v*(1-s/2)\n",
    "  s = tf.where((l==0) | (l==1),0.,(v-l)/tf.math.minimum(l,1-l))\n",
    "\n",
    "  hsl = tf.concat([h,s,l],axis=-1)\n",
    "  return hsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8MxE-OrBXIp"
   },
   "outputs": [],
   "source": [
    "def hsl_to_hsv(image):\n",
    "  h = image[...,0:1]\n",
    "  s = image[...,1:2]\n",
    "  l = image[...,2:3]\n",
    "\n",
    "  v = l + s*tf.math.minimum(l,1-l)\n",
    "  s = tf.where(v==0, 0., 2*(1-l/v))\n",
    "\n",
    "  hsv = tf.concat([h,s,v], axis=-1)\n",
    "  return hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4hG1BpMr_s4"
   },
   "outputs": [],
   "source": [
    "def output_to_rgb(image):\n",
    "  return image\n",
    "  # return denormalize(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyaP4hLJ8b4W"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_train(image, label):\n",
    "  image = tf.cast(image, tf.float32)/255.\n",
    "  image = random_jitter(image)\n",
    "  # image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VB3Z6D_zKSru"
   },
   "outputs": [],
   "source": [
    "def preprocess_image_test(image, label):\n",
    "  image = tf.cast(image, tf.float32)/255.\n",
    "  # image = normalize(image)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuGVPOo7Cce0"
   },
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n",
    "                              with_info=True, as_supervised=True)\n",
    "\n",
    "train_A, train_B = dataset['trainA'], dataset['trainB']\n",
    "test_A, test_B = dataset['testA'], dataset['testB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsajGXxd5JkZ"
   },
   "outputs": [],
   "source": [
    "train_A = train_A.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "train_B = train_B.map(\n",
    "    preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_A = test_A.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "test_B = test_B.map(\n",
    "    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
    "    BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3MhJ3zVLPan"
   },
   "outputs": [],
   "source": [
    "sample_A = next(iter(train_A))\n",
    "sample_B = next(iter(train_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4pOYjMk_KfIB"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('A')\n",
    "plt.imshow(output_to_rgb(sample_A[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('A with random jitter')\n",
    "plt.imshow(output_to_rgb(random_jitter(sample_A[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0KJyB9ENLb2y"
   },
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.title('B')\n",
    "plt.imshow(output_to_rgb(sample_B[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('B with random jitter')\n",
    "plt.imshow(output_to_rgb(random_jitter(sample_B[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvX8sKsfMaio"
   },
   "source": [
    "## Build Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ju9Wyw87MRW"
   },
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "# generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "# generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
    "\n",
    "# discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "# discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Y8cRApCHfKb"
   },
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2ihzN9mHhn5"
   },
   "outputs": [],
   "source": [
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(tf.expand_dims(sample_A[0], 0))\n",
    "print (down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11wgl1c3Hilh"
   },
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOj5VhQeHjHT"
   },
   "outputs": [],
   "source": [
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(down_result)\n",
    "print (up_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppAjXG2WNiRn"
   },
   "outputs": [],
   "source": [
    "def gauss_blur_model(input_shape, kernel_size=19, sigma=5, **kwargs):\n",
    "  import numpy as np\n",
    "  def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "      \"\"\"\n",
    "      2D gaussian mask - should give the same result as MATLAB's\n",
    "      fspecial('gaussian',[shape],[sigma])\n",
    "      #https://stackoverflow.com/questions/55643675/how-do-i-implement-gaussian-blurring-layer-in-keras\n",
    "      #https://stackoverflow.com/questions/17190649/how-to-obtain-a-gaussian-filter-in-python/17201686#17201686\n",
    "      \"\"\"\n",
    "      m,n = [(ss-1.)/2. for ss in shape]\n",
    "      y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "      h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "      h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "      sumh = h.sum()\n",
    "      if sumh != 0:\n",
    "          h /= sumh\n",
    "      return h  \n",
    "  class SymmetricPadding2D(tf.keras.layers.Layer):\n",
    "      #Source: https://stackoverflow.com/a/55210905/11394663\n",
    "      def __init__(self, output_dim, padding=[1,1], \n",
    "                  data_format=\"channels_last\", **kwargs):\n",
    "          self.output_dim = output_dim\n",
    "          self.data_format = data_format\n",
    "          self.padding = padding\n",
    "          super(SymmetricPadding2D, self).__init__(**kwargs)\n",
    "\n",
    "      def build(self, input_shape):\n",
    "          super(SymmetricPadding2D, self).build(input_shape)\n",
    "\n",
    "      def call(self, inputs):\n",
    "          if self.data_format is \"channels_last\":\n",
    "              #(batch, depth, rows, cols, channels)\n",
    "              pad = [[0,0]] + [[i,i] for i in self.padding] + [[0,0]]\n",
    "          elif self.data_format is \"channels_first\":\n",
    "              #(batch, channels, depth, rows, cols)\n",
    "              pad = [[0, 0], [0, 0]] + [[i,i] for i in self.padding]\n",
    "          paddings = tf.constant(pad)\n",
    "          out = tf.pad(inputs, paddings, \"REFLECT\")\n",
    "          return out \n",
    "\n",
    "      def compute_output_shape(self, input_shape):\n",
    "          return (input_shape[0], self.output_dim)  \n",
    "  if kernel_size % 2 == 0:\n",
    "    raise Exception(\"kernel size should be an odd number\")\n",
    "  gauss_inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "  #### Gaussian Blur #####\n",
    "  kernel_weights = matlab_style_gauss2D(shape=(kernel_size,kernel_size), sigma=sigma)\n",
    "  in_channels = input_shape[-1]\n",
    "  kernel_weights = np.expand_dims(kernel_weights, axis=-1)\n",
    "  kernel_weights = np.repeat(kernel_weights, in_channels, axis=-1) # apply the same filter on all the input channels\n",
    "  kernel_weights = np.expand_dims(kernel_weights, axis=-1)  # for shape compatibility reasons\n",
    "  gauss_layer = tf.keras.layers.DepthwiseConv2D(kernel_size, use_bias=False, padding='valid')\n",
    "  p = (kernel_size-1)//2\n",
    "  x = SymmetricPadding2D(0, padding=[p,p])(gauss_inputs)\n",
    "  x = gauss_layer(x)\n",
    "  ########################\n",
    "  gauss_layer.set_weights([kernel_weights])\n",
    "  gauss_layer.trainable = False\n",
    "  return tf.keras.Model(inputs=gauss_inputs, outputs=x, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqI9B_upHk3J"
   },
   "outputs": [],
   "source": [
    "def Generator():\n",
    " \n",
    "  inputs = tf.keras.layers.Input(shape=[256,256,3])\n",
    "\n",
    "  down_stack = [\n",
    "    downsample(64, 4, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
    "    downsample(128, 4), # (bs, 64, 64, 128)\n",
    "    downsample(256, 4), # (bs, 32, 32, 256)\n",
    "    downsample(512, 4), # (bs, 16, 16, 512)\n",
    "    downsample(512, 4), # (bs, 8, 8, 512)\n",
    "    downsample(512, 4), # (bs, 4, 4, 512)\n",
    "    downsample(512, 4), # (bs, 2, 2, 512)\n",
    "    downsample(512, 4), # (bs, 1, 1, 512)\n",
    "  ]\n",
    "\n",
    "  up_stack = [\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
    "    upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
    "    upsample(512, 4), # (bs, 16, 16, 1024)\n",
    "    upsample(256, 4), # (bs, 32, 32, 512)\n",
    "    upsample(128, 4), # (bs, 64, 64, 256)\n",
    "    upsample(64, 4), # (bs, 128, 128, 128)\n",
    "  ]\n",
    "\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "  last = tf.keras.layers.Conv2DTranspose(1, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         name = 'transmission_layer',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='sigmoid') # (bs, 256, 256, 1)\n",
    "\n",
    "  x = inputs\n",
    "  # channel1 = tf.keras.layers.Lambda(lambda x:x[:,:,:,0:1])(inputs)\n",
    "  # channel2 = tf.keras.layers.Lambda(lambda x:x[:,:,:,1:2])(inputs)\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = []\n",
    "  for down in down_stack:\n",
    "    x = down(x)\n",
    "    skips.append(x)\n",
    "\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "  transmission = last(x)\n",
    "  # transmission = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, [128, 128],\n",
    "                          # method=tf.image.ResizeMethod.GAUSSIAN))(transmission)\n",
    "  # transmission = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, [256, 256],\n",
    "                          # method=tf.image.ResizeMethod.GAUSSIAN), name='final_transmission_layer')(transmission)\n",
    "\n",
    "  transmission = gauss_blur_model([256,256,1],name=\"gauss_blur\")(transmission)\n",
    "\n",
    "  x = tf.keras.layers.multiply([inputs, transmission])\n",
    "  one_minus_t = tf.keras.layers.Lambda(lambda x:1-x, name='transmission_invert')(transmission)\n",
    "  x = tf.keras.layers.add([x,one_minus_t])\n",
    "  # x = tf.keras.layers.Concatenate()([channel1, channel2, channel3])\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1PlWxBqiHu1M"
   },
   "outputs": [],
   "source": [
    "generator_g = Generator()\n",
    "generator_f = Generator()\n",
    "tf.keras.utils.plot_model(generator_g, show_shapes=True, dpi=64)\n",
    "# discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
    "# discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDaGZ3WpZUyw"
   },
   "outputs": [],
   "source": [
    "to_B = generator_g(sample_A)\n",
    "to_A = generator_f(sample_B)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_A, to_B, sample_B, to_A]\n",
    "title = ['A', 'To B', 'B', 'To A']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "  plt.subplot(2, 2, i+1)\n",
    "  plt.title(title[i])\n",
    "  if i % 2 == 0:\n",
    "    plt.imshow(output_to_rgb(imgs[i][0]))\n",
    "  else:\n",
    "    plt.imshow(output_to_rgb(imgs[i][0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FsCfIhjeIDGM"
   },
   "source": [
    "## Build Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KDPrRahAH_wO"
   },
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "  # tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "\n",
    "  # x = tf.keras.layers.concatenate([inp, tar]) # (bs, 256, 256, channels*2)\n",
    "\n",
    "  down1 = downsample(64, 4, False)(inp) # (bs, 128, 128, 64)\n",
    "  down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
    "  down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSZb1ZsOIbhj"
   },
   "outputs": [],
   "source": [
    "discriminator_x = Discriminator()\n",
    "discriminator_y = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAp1Ob5ZMAKe"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(discriminator_x, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5MhJmxyZiy9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title('Is a real B?')\n",
    "plt.imshow(discriminator_y(sample_B)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title('Is a real A?')\n",
    "plt.imshow(discriminator_x(sample_A)[0, ..., -1], cmap='RdBu_r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyhxTuvJyIHV"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q1Xbz5OaLj5C"
   },
   "outputs": [],
   "source": [
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real, generated):\n",
    "  real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "  total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "  return total_disc_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(generated):\n",
    "  return loss_obj(tf.ones_like(generated), generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMpVGj_sW6Vo"
   },
   "outputs": [],
   "source": [
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "  \n",
    "  return LAMBDA * loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05ywEH680Aud"
   },
   "outputs": [],
   "source": [
    "def identity_loss(real_image, same_image):\n",
    "  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "  return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWCn_PVdEJZ7"
   },
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKUZnDiqQrAh"
   },
   "source": [
    "## Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ES2MVDZou5tG"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJnftd5sQsv6"
   },
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./drive/My Drive/Colab Notebooks/CycleGAN/tf_learn/06-train/\"\n",
    "checkpoint_path = \"./06-train/\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           generator_f=generator_f,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           discriminator_y=discriminator_y,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           generator_f_optimizer=generator_f_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')\n",
    "else:\n",
    "  print('No checkpoint found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NS2GWywBbAWo"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmdVsmvhPxyy"
   },
   "outputs": [],
   "source": [
    "def generate_images(modelA, test_inputA, modelB, test_inputB):\n",
    "  predictionA = modelA(test_inputA)\n",
    "  predictionB = modelB(test_inputB)\n",
    "    \n",
    "  plt.figure(figsize=(12, 12))\n",
    "\n",
    "  display_list = [test_inputA[0], predictionA[0], test_inputB[0], predictionB[0]]\n",
    "  title = ['A', 'To B', 'B', 'To A']\n",
    "\n",
    "  for i in range(4):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(title[i])\n",
    "    # getting the pixel values between [0, 1] to plot it.\n",
    "    plt.imshow(output_to_rgb(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pdds4yG3HTe4"
   },
   "outputs": [],
   "source": [
    "generate_images(generator_g, sample_A, generator_f, sample_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBKUV2sKXDbY"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "  # persistent is set to True because the tape is used more than\n",
    "  # once to calculate the gradients.\n",
    "  with tf.GradientTape(persistent=True) as tape:\n",
    "    # Generator G translates X -> Y\n",
    "    # Generator F translates Y -> X.\n",
    "    \n",
    "    fake_y = generator_g(real_x, training=True)\n",
    "    cycled_x = generator_f(fake_y, training=True)\n",
    "\n",
    "    fake_x = generator_f(real_y, training=True)\n",
    "    cycled_y = generator_g(fake_x, training=True)\n",
    "\n",
    "    # same_x and same_y are used for identity loss.\n",
    "    same_x = generator_f(real_x, training=True)\n",
    "    same_y = generator_g(real_y, training=True)\n",
    "\n",
    "    disc_real_x = discriminator_x(real_x, training=True)\n",
    "    disc_real_y = discriminator_y(real_y, training=True)\n",
    "\n",
    "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
    "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "    # calculate the loss\n",
    "    gen_g_loss = generator_loss(disc_fake_y)\n",
    "    gen_f_loss = generator_loss(disc_fake_x)\n",
    "    \n",
    "    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
    "    \n",
    "    # Total generator loss = adversarial loss + cycle loss\n",
    "    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
    "    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
    "\n",
    "    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
    "  \n",
    "  # Calculate the gradients for generator and discriminator\n",
    "  generator_g_gradients = tape.gradient(total_gen_g_loss, \n",
    "                                        generator_g.trainable_variables)\n",
    "  generator_f_gradients = tape.gradient(total_gen_f_loss, \n",
    "                                        generator_f.trainable_variables)\n",
    "  \n",
    "  discriminator_x_gradients = tape.gradient(disc_x_loss, \n",
    "                                            discriminator_x.trainable_variables)\n",
    "  discriminator_y_gradients = tape.gradient(disc_y_loss, \n",
    "                                            discriminator_y.trainable_variables)\n",
    "  \n",
    "  # Apply the gradients to the optimizer\n",
    "  generator_g_optimizer.apply_gradients(zip(generator_g_gradients, \n",
    "                                            generator_g.trainable_variables))\n",
    "\n",
    "  generator_f_optimizer.apply_gradients(zip(generator_f_gradients, \n",
    "                                            generator_f.trainable_variables))\n",
    "  \n",
    "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
    "                                                discriminator_x.trainable_variables))\n",
    "  \n",
    "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
    "                                                discriminator_y.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "length = \"Unknown\"\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  n = 0\n",
    "  # Using a consistent image (sample_A) so that the progress of the model\n",
    "  # is clearly visible.\n",
    "  for A, B in zip(test_A.take(1), test_B.take(1)):\n",
    "    generate_images(generator_g, A, generator_f, B)\n",
    "  dataset = tf.data.Dataset.zip((train_A, train_B))\n",
    "  for image_x, image_y in dataset:\n",
    "    # print(image_x.shape, image_y.shape)\n",
    "    train_step(image_x, image_y)\n",
    "    if(n%10==0):\n",
    "      print ('{}/{}'.format(n,length))\n",
    "    n+=1\n",
    "  length = n\n",
    "\n",
    "  clear_output(wait=True)\n",
    "\n",
    "  ckpt_save_path = ckpt_manager.save()\n",
    "  print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                        ckpt_save_path))\n",
    "\n",
    "  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
    "                                                      time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLnOk_xqvFNm"
   },
   "outputs": [],
   "source": [
    "sample_A = next(iter(test_A))\n",
    "sample_B = next(iter(test_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci0mR335UdrX"
   },
   "outputs": [],
   "source": [
    "gen = generator_g\n",
    "image = sample_A\n",
    "# Check Transmission map values\n",
    "model1 = tf.keras.Model(inputs = gen.inputs, outputs = gen.get_layer('transmission_layer').output)\n",
    "t = model1(image)\n",
    "model2 = tf.keras.Model(inputs = gen.inputs, outputs = gen.get_layer('transmission_invert').output)\n",
    "tgauss = model2(image)\n",
    "# t = tf.image.resize(t, [32, 32],\n",
    "#                           method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "# t = tf.image.resize(t, [256, 256],\n",
    "#                           method=tf.image.ResizeMethod.GAUSSIAN)\n",
    "plt.figure(figsize=(12,12)) \n",
    "plt.subplot(2,2,1)                       \n",
    "plt.imshow((1-t[0]).numpy().squeeze(), cmap='gray')\n",
    "plt.subplot(2,2,2)                       \n",
    "plt.imshow((tgauss[0]).numpy().squeeze(), cmap='gray')\n",
    "plt.subplot(2,2,3)                       \n",
    "plt.imshow((image).numpy().squeeze(), cmap='gray')\n",
    "plt.subplot(2,2,4)                       \n",
    "plt.imshow((gen(image)).numpy().squeeze(), cmap='gray')\n",
    "# generate_images(generator_g, sample_A, generator_f, sample_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgcbGlYMPGni"
   },
   "outputs": [],
   "source": [
    "gen.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Cycle-Foggy-GAN.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
